<app-slideshow-section>
  <ng-template>
    <div class="slide-content">
      <div class="split-slide">
        <div class="text-column">
          <h1>YOLO Framework</h1>
          <p>
            The YOLO (You Only Look Once) framework, developed and maintained by Ultralytics, is among the
            most powerful and widely adopted tools in modern computer vision. Initially introduced as a
            novel approach to object detection that formulates the task as a single-stage regression
            problem, YOLO has evolved through several versions—culminating in YOLOv11—with significant
            improvements in accuracy, speed, and usability. </p>

          <p>
            Its primary strength lies in the high inference speed of its models, which makes it suitable for
            real-time applications such as autonomous driving, security surveillance, and industrial
            inspection. YOLO provides a diverse suite of pre-trained models tailored for various computer
            vision tasks, including object detection, classification, and segmentation.
          </p>
          <p>
            Furthermore, the framework greatly simplifies the training process by abstracting away complex
            aspects such as class imbalance, data augmentation, and model optimization. This user-centric
            design makes it highly accessible for both researchers and practitioners.
          </p>
        </div>
        <div class="grid-wrapper">
          <div class="image-grid">
            <img src="assets/images/yolo/banner_detect.png" alt="Detection Banner" />
            <img src="assets/images/yolo/banner_segment.png" alt="Segmentation Banner" />
            <img src="assets/images/yolo/banner_classify.png" alt="Classification Banner" />
            <img src="assets/images/yolo/banner_pose.png" alt="Pose Banner" />
            <img src="assets/images/yolo/banner_obb.png" alt="Oriented Bounding Box Banner" />
            <img src="assets/images/yolo/banner_track.png" alt="Track Banner" />

          </div>
        </div>
      </div>
    </div>
  </ng-template>

  <ng-template>
    <div class="slide-content">
      <div class="split-slide">
        <div class="text-column">
          <h1>YOLOv8 Classification Results</h1>
          <p>
            The first model trained in this study is the YOLOv8 Classification model. This process involves fine-tuning
            a pretrained classification model from the YOLO framework to develop a functional system capable of
            accurately classifying the condition of the components. The model is trained for a total of 100 epochs.
          </p>
          <div class="image-wrapper">
            <img src="assets/snippets/yolo_train.svg" alt="YOLOv8 Classification Model Train Function">
          </div>
        </div>
        <div class="result-column">
          <div class="chart-wrapper">
            <div class="zoom-reset-wrapper">
              <p-button label="Reset Zoom" [rounded]="false" severity="secondary" (onClick)="resetZoomCls()" />
            </div>
            <p-chart #clsChart type="line" [data]="chartData" [options]="chartOptions"></p-chart>
          </div>
          <div class="table-wrapper">
            <p-table [value]="users" responsiveLayout="scroll">
              <ng-template pTemplate="header">
                <tr>
                  <th>Class</th>
                  <th>Precision</th>
                  <th>Recall</th>
                  <th>F1-score</th>
                  <th>Support</th>
                </tr>

              </ng-template>
              <ng-template pTemplate="body" let-user>
                <tr>
                  <td>{{ user.class }}</td>
                  <td>{{ user.precision }}</td>
                  <td>{{ user.recall }}</td>
                  <td>{{ user.f1 }}</td>
                  <td>{{ user.support }}</td>
                </tr>
              </ng-template>
              <ng-template pTemplate="footer">
                <tr>
                  <td colspan="5">
                    <div style="display: flex; justify-content: center; align-items: center;">
                      <p style="margin: auto;"><strong sty>Accuracy: 99.86%</strong></p>
                      <p style="margin: auto;"><strong sty>Inference Time: 3.98 ms</strong></p>
                    </div>
                  </td>
                </tr>
              </ng-template>
            </p-table>
          </div>
        </div>
      </div>
    </div>
  </ng-template>



  <ng-template>
    <div class="slide-content">
      <div class="split-slide">
        <div class="text-column">
          <h1>Semi-supervised Learning</h1>
          <p>
            The semi-supervised paradigm combines a small amount of labeled data with a large amount of unlabeled data
            to improve learning performance. It leverages the structure in unlabeled data to guide the model, making it
            especially useful when labeled data is scarce or costly. This approach balances the strengths of supervised
            and unsupervised learning.
          </p>
          <p>
            The semi-supervised paradigm is used to train segmentation models capable of distinguishing between the
            interior and the background of the part. The Roboflow tool is employed to label the regions of the image
            corresponding to the part. </p>
        </div>
        <div class="grid-wrapper">
          <div class="image-grid_2">
            <img src="assets/images/semisupervised/semisupervised_flow1.svg" alt="Semi Supervised Flow" />
            <img src="assets/images/semisupervised/semisupervised_flow2.svg" alt="Semi Supervised Flow" />
            <img src="assets/images/semisupervised/semisupervised_flow3.svg" alt="Semi Supervised Flow" />
          </div>
        </div>
      </div>
    </div>
  </ng-template>

  <ng-template>
    <div class="slide-content">
      <div class="split-slide">
        <div class="text-column">
          <h1>YOLOv8 Segmentation Results</h1>
          <h2>First Segmenter</h2>
          <p>
            The initial segmentation model, developed using a supervised learning paradigm and trained on a relatively
            small dataset comprising only 100 annotated images, has already yielded good results. Despite the limited
            amount of training data, the model demonstrates a notable ability to accurately delineate target regions.
          </p>
          <div class="grid-wrapper">
            <div class="image-grid_3">
              <img src="assets/images/segmentation/seg_val_true.png" alt="YOLOv8 Classification Model Train Function">
              <img src="assets/images/segmentation/seg_val_pred.png" alt="YOLOv8 Classification Model Train Function">
            </div>
          </div>
        </div>

        <div class="result-column">
          <div class="chart-wrapper">
            <div class="zoom-reset-wrapper">
              <p-button label="Reset Zoom" [rounded]="false" severity="secondary" (onClick)="resetZoomSeg1()" />
            </div>
            <p-chart #segChart1 type="line" [data]="chartDataSeg1" [options]="chartOptionsSeg"></p-chart>
          </div>
          <div class="table-wrapper">
            <p-table [value]="seg1" responsiveLayout="scroll">
              <ng-template pTemplate="header">
                <tr>
                  <th>mIoU</th>
                  <th>Dice</th>
                  <th>Inference Time [ms]</th>
                </tr>

              </ng-template>
              <ng-template pTemplate="body" let-seg1>
                <tr>
                  <td>{{ seg1.miou }}</td>
                  <td>{{ seg1.dice }}</td>
                  <td>{{ seg1.inference_time }}</td>
                </tr>
              </ng-template>
            </p-table>
          </div>
        </div>
      </div>

    </div>
  </ng-template>


  <ng-template>
    <div class="slide-content">
      <div class="split-slide">
        <div class="text-column">
          <h1>YOLOv8 Segmentation Results</h1>
          <h2>Second Segmenter</h2>
          <p>
            The second segmentation model, trained on a pseudo-labeled dataset within a semi-supervised learning
            framework, demonstrates a slight improvement over the baseline model trained under a purely supervised
            paradigm. This approach enhances the model’s generalization capabilities, leading to more accurate and
            robust segmentation performance compared to the initial supervised counterpart.
          </p>
          <div class="grid-wrapper">
            <div class="image-grid_4">
              <img src="assets/images/segmentation/mosaic/seg_augmentation-0-0.png"
                alt="Segmentation Augmentation Mosaic">
              <img src="assets/images/segmentation/mosaic/seg_augmentation-0-1.png"
                alt="Segmentation Augmentation Mosaic">
              <img src="assets/images/segmentation/mosaic/seg_augmentation-0-2.png"
                alt="Segmentation Augmentation Mosaic">
              <img src="assets/images/segmentation/mosaic/seg_augmentation-0-3.png"
                alt="Segmentation Augmentation Mosaic">
              <img src="assets/images/segmentation/mosaic/seg_augmentation-1-0.png"
                alt="Segmentation Augmentation Mosaic">
              <img src="assets/images/segmentation/mosaic/seg_augmentation-1-1.png"
                alt="Segmentation Augmentation Mosaic">
              <img src="assets/images/segmentation/mosaic/seg_augmentation-1-2.png"
                alt="Segmentation Augmentation Mosaic">
              <img src="assets/images/segmentation/mosaic/seg_augmentation-1-3.png"
                alt="Segmentation Augmentation Mosaic">
              <img src="assets/images/segmentation/mosaic/seg_augmentation-2-0.png"
                alt="Segmentation Augmentation Mosaic">
              <img src="assets/images/segmentation/mosaic/seg_augmentation-2-1.png"
                alt="Segmentation Augmentation Mosaic">
              <!-- <img src="assets/images/segmentation/mosaic/seg_augmentation-2-2.png" alt="Segmentation Augmentation Mosaic">
            <img src="assets/images/segmentation/mosaic/seg_augmentation-2-3.png" alt="Segmentation Augmentation Mosaic">
            <img src="assets/images/segmentation/mosaic/seg_augmentation-3-0.png" alt="Segmentation Augmentation Mosaic">
            <img src="assets/images/segmentation/mosaic/seg_augmentation-3-1.png" alt="Segmentation Augmentation Mosaic">
            <img src="assets/images/segmentation/mosaic/seg_augmentation-3-2.png" alt="Segmentation Augmentation Mosaic"> -->
              <!-- <img src="assets/images/segmentation/mosaic/seg_augmentation-3-3.png" alt="Segmentation Augmentation Mosaic"> -->
            </div>
          </div>
        </div>

        <div class="result-column">
          <div class="chart-wrapper">
            <div class="zoom-reset-wrapper">
              <p-button label="Reset Zoom" [rounded]="false" severity="secondary" (onClick)="resetZoomSeg2()" />
            </div>
            <p-chart #segChart2 type="line" [data]="chartDataSeg2" [options]="chartOptionsSeg"></p-chart>
          </div>
          <div class="table-wrapper">
            <p-table [value]="seg2" responsiveLayout="scroll">
              <ng-template pTemplate="header">
                <tr>
                  <th>mIoU</th>
                  <th>Dice</th>
                  <th>Inference Time [ms]</th>
                </tr>

              </ng-template>
              <ng-template pTemplate="body" let-seg2>
                <tr>
                  <td>{{ seg2.miou }}</td>
                  <td>{{ seg2.dice }}</td>
                  <td>{{ seg2.inference_time }}</td>
                </tr>
              </ng-template>
            </p-table>
          </div>
        </div>
      </div>
      <div class="next-btn-div">
        <button class="next-btn" (click)="goNext()">
          Keras Framework <span class="arrow">→</span>
        </button>
      </div>
    </div>
  </ng-template>

</app-slideshow-section>