<app-slideshow-section>

  <ng-template>
    <div class="slide-content">
      <div class="split-slide">
        <div class="text-column">
          <h1>GradCAM</h1>
          <p>
            Gradient-weighted Class Activation Mapping (Grad-CAM) is a prominent technique in Explainable Artificial Intelligence (XAI) that enhances the interpretability of convolutional neural networks (CNNs). It generates class-specific heatmaps that highlight the regions of an input image most influential in a model’s decision, enabling users to visualize and understand the reasoning behind predictions. Unlike earlier methods, Grad-CAM does not require changes to the model architecture or retraining, making it compatible with a wide range of pre-trained networks.
          </p>
          <p>
            The method operates by computing the gradient of the output for a target class with respect to the feature maps of a selected convolutional layer. These gradients are globally averaged to produce importance weights, which are then used to compute a weighted sum of the feature maps. Applying a ReLU activation isolates the positively contributing features, and the resulting heatmap is upsampled and overlaid on the original image to indicate areas of high relevance.
          </p>
          <p>
            Grad-CAM is particularly useful for model validation and debugging, as it helps determine whether a model is focusing on semantically meaningful regions or relying on irrelevant cues. In sensitive domains such as healthcare and autonomous systems, this transparency fosters trust and supports accountability. As part of the broader goals of XAI, Grad-CAM plays a crucial role in promoting the responsible deployment of deep learning models by making their internal decision processes more interpretable and accessible.
          </p>

        </div>
        <div class="image-column">
          <div class="image-compare-wrapper">
            <p-imagecompare>
              <ng-template #left>
                <img class="gradcam-dog" src="assets/images/gradcam/grad_cam_dog.jpg" alt="Model Diagram" />
              </ng-template>
              <ng-template #right>
                <img class="gradcam-dog" src="assets/images/gradcam/grad_cam_dog_prev.jpg" alt="Model Diagram" />
              </ng-template>
            </p-imagecompare>
          </div>
        </div>
      </div>
    </div>
  </ng-template>


  <ng-template>
    <div class="slide-content">
      <div class="split-slide">
        <div class="text-column">
          <h1>GradCAM</h1>
          <h2>Experiment with Pre-trained DenseNet121</h2>
          <p>
          Evaluation on the held-out test set confirmed that the network retained adequate predictive capability, validating the use of Grad-CAM for post-hoc interpretability. Heatmaps generated over the same test images consistently localized the most salient defect regions, mirroring the focal points a skilled human inspector would intuitively examine. This congruence between model attention and human reasoning substantiates the explanatory power of Grad-CAM and reinforces confidence in the automated system’s decision-making process.
        </p>
          <p>
More challenging cases—those containing multiple subtle or diffuse defects—produced correspondingly dispersed activation patterns, indicating that the classifier aggregated evidence from several minor anomalies rather than relying on a single dominant feature. Although such heatmaps can appear less self-explanatory, they still expose the model’s internal weighting of ambiguous cues and thus remain valuable for debugging and refinement. Overall, the experiment demonstrates that Grad-CAM not only enhances the transparency of deep CNNs in industrial defect detection but also offers practical guidance for improving model reliability in complex visual scenarios.
</p>
          <div class="next-btn-div">
            <button class="next-btn" (click)="goNext()">
              Conclusion <span class="arrow">→</span>
            </button>
          </div>
        </div>
        <div class="image-column">
          <div class="gradcam-wrapper">
            <div class="gradcam-select-wrapper">
              <p-selectbutton [allowEmpty]="false" [options]="stateOptions" [(ngModel)]="value" optionLabel="label"
                optionValue="value" aria-labelledby="basic" />
            </div>
            <div class="gradcam-image-grid">
              @for (img of displayedImages; track img) {
              <img [src]="img" class="gradcam-grid-img fade" [class.show]="imagesVisible" alt="GradCAM" />
              }
            </div>
          </div>



          <!-- <p-imagecompare class="shadow-lg rounded-2xl">
                    <ng-template #left>
                        <img src="https://primefaces.org/cdn/primevue/images/compare/island1.jpg" />
                    </ng-template>
                    <ng-template #right>
                        <img src="https://primefaces.org/cdn/primevue/images/compare/island2.jpg" />
                    </ng-template>
                </p-imagecompare>                 -->
        </div>
      </div>
    </div>
  </ng-template>

</app-slideshow-section>